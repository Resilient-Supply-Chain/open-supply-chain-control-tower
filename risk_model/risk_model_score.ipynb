{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Risk Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "df = pd.read_csv('california_risk_model_data_dec2022_mar2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "join-header",
   "metadata": {},
   "source": [
    "## Join with Risk Model Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "join-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data shape: (7018, 41)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_code</th>\n",
       "      <th>county_name</th>\n",
       "      <th>date</th>\n",
       "      <th>ivt_max</th>\n",
       "      <th>ar_intensity</th>\n",
       "      <th>gage_height_mean</th>\n",
       "      <th>streamflow_mean</th>\n",
       "      <th>wind_speed_max</th>\n",
       "      <th>wind_gust_max</th>\n",
       "      <th>precip_total</th>\n",
       "      <th>runoff_total</th>\n",
       "      <th>temp_anomaly</th>\n",
       "      <th>soil_moisture_mean</th>\n",
       "      <th>IVT_max</th>\n",
       "      <th>IVT_duration</th>\n",
       "      <th>AR_category</th>\n",
       "      <th>Precip_24h</th>\n",
       "      <th>Precip_72h</th>\n",
       "      <th>Wind_gust_max</th>\n",
       "      <th>Soil_moisture_pct</th>\n",
       "      <th>API_7d</th>\n",
       "      <th>API_14d</th>\n",
       "      <th>Snowpack_SWE</th>\n",
       "      <th>Temp_anomaly</th>\n",
       "      <th>Streamflow_pct</th>\n",
       "      <th>Streamflow_p95_exceed</th>\n",
       "      <th>Runoff_ratio</th>\n",
       "      <th>Flood_stage_exceed</th>\n",
       "      <th>AR_count_7d</th>\n",
       "      <th>AR_count_14d</th>\n",
       "      <th>Wet_days_10</th>\n",
       "      <th>Dry_gap</th>\n",
       "      <th>Population_exposed</th>\n",
       "      <th>Infrastructure_density</th>\n",
       "      <th>County_area</th>\n",
       "      <th>Agricultural_share</th>\n",
       "      <th>start_time</th>\n",
       "      <th>county</th>\n",
       "      <th>duration</th>\n",
       "      <th>max_customers</th>\n",
       "      <th>risk score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>517.876160</td>\n",
       "      <td>AR2</td>\n",
       "      <td>3.363378</td>\n",
       "      <td>8.844656</td>\n",
       "      <td>10.958761</td>\n",
       "      <td>28.427376</td>\n",
       "      <td>3.846169</td>\n",
       "      <td>0.067472</td>\n",
       "      <td>2.004796</td>\n",
       "      <td>0.180444</td>\n",
       "      <td>517.876160</td>\n",
       "      <td>12</td>\n",
       "      <td>AR2</td>\n",
       "      <td>3.846169</td>\n",
       "      <td>3.846169</td>\n",
       "      <td>28.427376</td>\n",
       "      <td>0.180444</td>\n",
       "      <td>3.846169</td>\n",
       "      <td>3.846169</td>\n",
       "      <td>80</td>\n",
       "      <td>2.004796</td>\n",
       "      <td>56.250</td>\n",
       "      <td>-0.990279</td>\n",
       "      <td>0.017543</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2022-12-02</td>\n",
       "      <td>231.908783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.363423</td>\n",
       "      <td>9.136874</td>\n",
       "      <td>6.120897</td>\n",
       "      <td>11.851345</td>\n",
       "      <td>0.020504</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>-2.666713</td>\n",
       "      <td>0.343442</td>\n",
       "      <td>231.908783</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020504</td>\n",
       "      <td>3.866673</td>\n",
       "      <td>11.851345</td>\n",
       "      <td>0.343442</td>\n",
       "      <td>3.482056</td>\n",
       "      <td>3.674364</td>\n",
       "      <td>80</td>\n",
       "      <td>-2.666713</td>\n",
       "      <td>59.375</td>\n",
       "      <td>-0.989958</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2022-12-03</td>\n",
       "      <td>456.337891</td>\n",
       "      <td>AR1</td>\n",
       "      <td>3.365482</td>\n",
       "      <td>7.298010</td>\n",
       "      <td>5.717101</td>\n",
       "      <td>9.304350</td>\n",
       "      <td>0.570774</td>\n",
       "      <td>0.009298</td>\n",
       "      <td>-2.150843</td>\n",
       "      <td>0.315793</td>\n",
       "      <td>456.337891</td>\n",
       "      <td>12</td>\n",
       "      <td>AR1</td>\n",
       "      <td>0.570774</td>\n",
       "      <td>4.437447</td>\n",
       "      <td>9.304350</td>\n",
       "      <td>0.315793</td>\n",
       "      <td>3.666162</td>\n",
       "      <td>4.051805</td>\n",
       "      <td>80</td>\n",
       "      <td>-2.150843</td>\n",
       "      <td>46.875</td>\n",
       "      <td>-0.991979</td>\n",
       "      <td>0.016291</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2022-12-04</td>\n",
       "      <td>550.994995</td>\n",
       "      <td>AR2</td>\n",
       "      <td>3.800255</td>\n",
       "      <td>41.210267</td>\n",
       "      <td>6.267160</td>\n",
       "      <td>22.702106</td>\n",
       "      <td>1.450539</td>\n",
       "      <td>0.032067</td>\n",
       "      <td>0.536351</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>550.994995</td>\n",
       "      <td>12</td>\n",
       "      <td>AR2</td>\n",
       "      <td>1.450539</td>\n",
       "      <td>2.041817</td>\n",
       "      <td>22.702106</td>\n",
       "      <td>0.388857</td>\n",
       "      <td>4.672956</td>\n",
       "      <td>5.280471</td>\n",
       "      <td>80</td>\n",
       "      <td>0.536351</td>\n",
       "      <td>78.125</td>\n",
       "      <td>-0.954708</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>330.216705</td>\n",
       "      <td>AR1</td>\n",
       "      <td>3.439359</td>\n",
       "      <td>8.097739</td>\n",
       "      <td>6.848634</td>\n",
       "      <td>18.281908</td>\n",
       "      <td>0.118732</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>3.223302</td>\n",
       "      <td>0.352034</td>\n",
       "      <td>330.216705</td>\n",
       "      <td>12</td>\n",
       "      <td>AR1</td>\n",
       "      <td>0.118732</td>\n",
       "      <td>2.140045</td>\n",
       "      <td>18.281908</td>\n",
       "      <td>0.352034</td>\n",
       "      <td>4.202890</td>\n",
       "      <td>5.104804</td>\n",
       "      <td>80</td>\n",
       "      <td>3.223302</td>\n",
       "      <td>53.125</td>\n",
       "      <td>-0.991100</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   county_code county_name       date     ivt_max ar_intensity  \\\n",
       "0         6001     Alameda 2022-12-01  517.876160          AR2   \n",
       "1         6001     Alameda 2022-12-02  231.908783          NaN   \n",
       "2         6001     Alameda 2022-12-03  456.337891          AR1   \n",
       "3         6001     Alameda 2022-12-04  550.994995          AR2   \n",
       "4         6001     Alameda 2022-12-05  330.216705          AR1   \n",
       "\n",
       "   gage_height_mean  streamflow_mean  wind_speed_max  wind_gust_max  \\\n",
       "0          3.363378         8.844656       10.958761      28.427376   \n",
       "1          3.363423         9.136874        6.120897      11.851345   \n",
       "2          3.365482         7.298010        5.717101       9.304350   \n",
       "3          3.800255        41.210267        6.267160      22.702106   \n",
       "4          3.439359         8.097739        6.848634      18.281908   \n",
       "\n",
       "   precip_total  runoff_total  temp_anomaly  soil_moisture_mean     IVT_max  \\\n",
       "0      3.846169      0.067472      2.004796            0.180444  517.876160   \n",
       "1      0.020504      0.000238     -2.666713            0.343442  231.908783   \n",
       "2      0.570774      0.009298     -2.150843            0.315793  456.337891   \n",
       "3      1.450539      0.032067      0.536351            0.388857  550.994995   \n",
       "4      0.118732      0.001907      3.223302            0.352034  330.216705   \n",
       "\n",
       "   IVT_duration AR_category  Precip_24h  Precip_72h  Wind_gust_max  \\\n",
       "0            12         AR2    3.846169    3.846169      28.427376   \n",
       "1             0         NaN    0.020504    3.866673      11.851345   \n",
       "2            12         AR1    0.570774    4.437447       9.304350   \n",
       "3            12         AR2    1.450539    2.041817      22.702106   \n",
       "4            12         AR1    0.118732    2.140045      18.281908   \n",
       "\n",
       "   Soil_moisture_pct    API_7d   API_14d  Snowpack_SWE  Temp_anomaly  \\\n",
       "0           0.180444  3.846169  3.846169            80      2.004796   \n",
       "1           0.343442  3.482056  3.674364            80     -2.666713   \n",
       "2           0.315793  3.666162  4.051805            80     -2.150843   \n",
       "3           0.388857  4.672956  5.280471            80      0.536351   \n",
       "4           0.352034  4.202890  5.104804            80      3.223302   \n",
       "\n",
       "   Streamflow_pct  Streamflow_p95_exceed  Runoff_ratio  Flood_stage_exceed  \\\n",
       "0          56.250              -0.990279      0.017543                   0   \n",
       "1          59.375              -0.989958      0.011628                   0   \n",
       "2          46.875              -0.991979      0.016291                   0   \n",
       "3          78.125              -0.954708      0.022107                   0   \n",
       "4          53.125              -0.991100      0.016064                   0   \n",
       "\n",
       "   AR_count_7d  AR_count_14d  Wet_days_10  Dry_gap  Population_exposed  \\\n",
       "0          1.0           1.0          1.0        0              100000   \n",
       "1          1.0           1.0          1.0        1              100000   \n",
       "2          2.0           2.0          1.0        2              100000   \n",
       "3          3.0           3.0          2.0        0              100000   \n",
       "4          4.0           4.0          2.0        1              100000   \n",
       "\n",
       "   Infrastructure_density  County_area  Agricultural_share start_time county  \\\n",
       "0                     2.0         5000                0.45        NaT    NaN   \n",
       "1                     2.0         5000                0.45        NaT    NaN   \n",
       "2                     2.0         5000                0.45        NaT    NaN   \n",
       "3                     2.0         5000                0.45        NaT    NaN   \n",
       "4                     2.0         5000                0.45        NaT    NaN   \n",
       "\n",
       "   duration  max_customers  risk score  \n",
       "0       NaN            NaN         NaN  \n",
       "1       NaN            NaN         NaN  \n",
       "2       NaN            NaN         NaN  \n",
       "3       NaN            NaN         NaN  \n",
       "4       NaN            NaN         NaN  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_y = pd.read_csv('risk_model_y.csv')\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "risk_y['start_time'] = pd.to_datetime(risk_y['start_time'])\n",
    "\n",
    "merged = df.merge(\n",
    "    risk_y, \n",
    "    left_on=['county_name', 'date'], \n",
    "    right_on=['county', 'start_time'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Merged data shape: {merged.shape}\")\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-header",
   "metadata": {},
   "source": [
    "## Clean Up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop specified columns\n",
    "columns_to_drop = ['max_customers', 'duration', 'start_time', 'county', \n",
    "                   'Population_exposed', 'Infrastructure_density', \n",
    "                   'County_area', 'Agricultural_share', 'ar_intensity']\n",
    "\n",
    "merged = merged.drop(columns=columns_to_drop, errors='ignore')\n",
    "merged['risk score'] = merged['risk score'].fillna(0)\n",
    "\n",
    "# Fill AR_category null values with 'N/A'\n",
    "merged['AR_category'] = merged['AR_category'].fillna('No AR')\n",
    "\n",
    "cols = ['gage_height_mean', 'streamflow_mean', 'Streamflow_pct']\n",
    "\n",
    "for col in cols:\n",
    "    county_mean = merged.groupby('county_name')[col].transform('mean')\n",
    "    global_mean = merged[col].mean()\n",
    "    merged[col] = merged[col].fillna(county_mean.fillna(global_mean))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ml-header",
   "metadata": {},
   "source": [
    "## Machine Learning Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ml-prep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7018, 28)\n",
      "Target shape: (7018,)\n",
      "\n",
      "Target distribution:\n",
      "risk score\n",
      "0    6794\n",
      "1     224\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Feature columns: ['ivt_max', 'gage_height_mean', 'streamflow_mean', 'wind_speed_max', 'wind_gust_max', 'precip_total', 'runoff_total', 'temp_anomaly', 'soil_moisture_mean', 'IVT_max', 'IVT_duration', 'Precip_24h', 'Precip_72h', 'Wind_gust_max', 'Soil_moisture_pct', 'API_7d', 'API_14d', 'Snowpack_SWE', 'Temp_anomaly', 'Streamflow_pct', 'Streamflow_p95_exceed', 'Runoff_ratio', 'Flood_stage_exceed', 'AR_count_7d', 'AR_count_14d', 'Wet_days_10', 'Dry_gap', 'AR_category_encoded']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data for ML\n",
    "ml_data = merged.copy()\n",
    "\n",
    "# Exclude county_code, county_name, date from features\n",
    "exclude_cols = ['county_code', 'county_name', 'date', 'risk score']\n",
    "feature_cols = [col for col in ml_data.columns if col not in exclude_cols]\n",
    "\n",
    "# Encode categorical variable AR_category\n",
    "le = LabelEncoder()\n",
    "ml_data['AR_category_encoded'] = le.fit_transform(ml_data['AR_category'])\n",
    "\n",
    "# Update feature columns\n",
    "feature_cols = [col for col in feature_cols if col != 'AR_category'] + ['AR_category_encoded']\n",
    "\n",
    "# Prepare X and y\n",
    "X = ml_data[feature_cols]\n",
    "y = ml_data['risk score'].astype(int)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nFeature columns: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ml-split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5614\n",
      "Test set size: 1404\n",
      "\n",
      "Training set target distribution:\n",
      "risk score\n",
      "0    5435\n",
      "1     179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test set target distribution:\n",
      "risk score\n",
      "0    1359\n",
      "1      45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"\\nTraining set target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set target distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ml-train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model...\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest model...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ml-evaluate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation:\n",
      "\n",
      "Accuracy: 0.9687\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1359\n",
      "           1       0.56      0.11      0.19        45\n",
      "\n",
      "    accuracy                           0.97      1404\n",
      "   macro avg       0.76      0.55      0.58      1404\n",
      "weighted avg       0.96      0.97      0.96      1404\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1355    4]\n",
      " [  40    5]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Model Evaluation:\")\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improve-recall",
   "metadata": {},
   "source": [
    "## Improve Recall for Class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "class-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "risk score\n",
      "0    5435\n",
      "1     179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class imbalance ratio: 30.36:1\n",
      "\n",
      "Class weights: {0: np.float64(0.5164673413063477), 1: np.float64(15.681564245810057)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "print(\"Class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nClass imbalance ratio: {y_train.value_counts()[0] / y_train.value_counts()[1]:.2f}:1\")\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "print(f\"\\nClass weights: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "smote-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "train-multiple-models",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 0.42s\n",
      "\n",
      "Training Decision Tree...\n",
      "Completed in 0.24s\n",
      "\n",
      "Training Random Forest...\n",
      "Completed in 0.72s\n",
      "\n",
      "Training Gradient Boosting...\n",
      "Completed in 9.94s\n",
      "\n",
      "Training AdaBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 2.31s\n",
      "\n",
      "Training XGBoost...\n",
      "Completed in 0.26s\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON (sorted by Recall for Class 1)\n",
      "================================================================================\n",
      "              Model  Accuracy  Precision_Class1  Recall_Class1  F1_Class1  Train_Time\n",
      "Logistic Regression  0.813390          0.121951       0.777778   0.210843    0.417224\n",
      "      Random Forest  0.960826          0.413793       0.533333   0.466019    0.717731\n",
      "      Decision Tree  0.923789          0.207547       0.488889   0.291391    0.238053\n",
      "            XGBoost  0.955840          0.355932       0.466667   0.403846    0.255770\n",
      "           AdaBoost  0.926638          0.204082       0.444444   0.279720    2.306607\n",
      "  Gradient Boosting  0.966524          0.473684       0.400000   0.433735    9.937970\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(class_weight='balanced', max_depth=15, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=15, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, max_depth=5, scale_pos_weight=30, random_state=42, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred_model = model.predict(X_test)\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred_model),\n",
    "        'Precision_Class1': precision_score(y_test, y_pred_model),\n",
    "        'Recall_Class1': recall_score(y_test, y_pred_model),\n",
    "        'F1_Class1': f1_score(y_test, y_pred_model),\n",
    "        'Train_Time': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Completed in {train_time:.2f}s\")\n",
    "\n",
    "model_comparison = pd.DataFrame(results).sort_values('Recall_Class1', ascending=False)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON (sorted by Recall for Class 1)\")\n",
    "print(\"=\"*80)\n",
    "print(model_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "detailed-evaluation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Logistic Regression - Detailed Report\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89      1359\n",
      "           1       0.12      0.78      0.21        45\n",
      "\n",
      "    accuracy                           0.81      1404\n",
      "   macro avg       0.56      0.80      0.55      1404\n",
      "weighted avg       0.96      0.81      0.87      1404\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1107  252]\n",
      " [  10   35]]\n",
      "\n",
      "True Negatives: 1107, False Positives: 252\n",
      "False Negatives: 10, True Positives: 35\n",
      "\n",
      "================================================================================\n",
      "Random Forest - Detailed Report\n",
      "================================================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1359\n",
      "           1       0.41      0.53      0.47        45\n",
      "\n",
      "    accuracy                           0.96      1404\n",
      "   macro avg       0.70      0.75      0.72      1404\n",
      "weighted avg       0.97      0.96      0.96      1404\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1325   34]\n",
      " [  21   24]]\n",
      "\n",
      "True Negatives: 1325, False Positives: 34\n",
      "False Negatives: 21, True Positives: 24\n",
      "\n",
      "================================================================================\n",
      "Decision Tree - Detailed Report\n",
      "================================================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1359\n",
      "           1       0.21      0.49      0.29        45\n",
      "\n",
      "    accuracy                           0.92      1404\n",
      "   macro avg       0.59      0.71      0.63      1404\n",
      "weighted avg       0.96      0.92      0.94      1404\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1275   84]\n",
      " [  23   22]]\n",
      "\n",
      "True Negatives: 1275, False Positives: 84\n",
      "False Negatives: 23, True Positives: 22\n"
     ]
    }
   ],
   "source": [
    "# Detailed evaluation of top 3 models\n",
    "top_models = model_comparison.head(3)['Model'].tolist()\n",
    "\n",
    "for model_name in top_models:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{model_name} - Detailed Report\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    model = models[model_name]\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred_model = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_model))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, y_pred_model)\n",
    "    print(cm)\n",
    "    print(f\"\\nTrue Negatives: {cm[0,0]}, False Positives: {cm[0,1]}\")\n",
    "    print(f\"False Negatives: {cm[1,0]}, True Positives: {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best-model-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model for Class 1 Recall: Logistic Regression\n",
      "Recall: 0.7778\n",
      "Precision: 0.1220\n",
      "F1 Score: 0.2108\n",
      "\n",
      "Final predictions saved to risk_model_predictions_best.csv\n",
      "\n",
      "Predicted risk score statistics (0-1 scale):\n",
      "count    7.018000e+03\n",
      "mean     2.452568e-01\n",
      "std      2.785584e-01\n",
      "min      3.612995e-07\n",
      "25%      2.842306e-02\n",
      "50%      1.150691e-01\n",
      "75%      3.902627e-01\n",
      "max      9.993807e-01\n",
      "Name: predicted_risk_score, dtype: float64\n",
      "\n",
      "Sample predictions:\n",
      "   county_name       date  risk score  predicted_risk_score\n",
      "9      Alameda 2022-12-10         0.0              0.542350\n",
      "10     Alameda 2022-12-11         0.0              0.545634\n",
      "26     Alameda 2022-12-27         0.0              0.754458\n",
      "30     Alameda 2022-12-31         0.0              0.860257\n",
      "32      Alpine 2022-12-02         0.0              0.894106\n",
      "33      Alpine 2022-12-03         0.0              0.678616\n",
      "34      Alpine 2022-12-04         0.0              0.895378\n",
      "35      Alpine 2022-12-05         0.0              0.735474\n",
      "36      Alpine 2022-12-06         0.0              0.709420\n",
      "40      Alpine 2022-12-10         0.0              0.547588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Select best model based on recall\n",
    "best_model_name = model_comparison.iloc[0]['Model']\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best model for Class 1 Recall: {best_model_name}\")\n",
    "print(f\"Recall: {model_comparison.iloc[0]['Recall_Class1']:.4f}\")\n",
    "print(f\"Precision: {model_comparison.iloc[0]['Precision_Class1']:.4f}\")\n",
    "print(f\"F1 Score: {model_comparison.iloc[0]['F1_Class1']:.4f}\")\n",
    "\n",
    "# Train on full SMOTE data and predict probability scores\n",
    "best_model.fit(X_train_smote, y_train_smote)\n",
    "ml_data['predicted_risk_score'] = best_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Save final results\n",
    "final_results = ml_data[['county_name', 'date', 'risk score', 'predicted_risk_score']].copy()\n",
    "final_results.to_csv('risk_model_score_predictions.csv', index=False)\n",
    "\n",
    "print(f\"\\nFinal predictions saved to risk_model_score_predictions.csv\")\n",
    "print(f\"\\nPredicted risk score statistics (0-1 scale):\")\n",
    "print(final_results['predicted_risk_score'].describe())\n",
    "print(f\"\\nSample predictions:\")\n",
    "print(final_results[final_results['predicted_risk_score'] > 0.5].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd693ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
